---
title: "Lab 8: Data Augmentation"
author: "Olivier Binette"
date: "Friday October 9, 2020"
fontsize: 11pt
output: 
  beamer_presentation:
    include:
      in_header: preamble.tex
---

```{r, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=4, fig.height=3, fig.align="center")
set.seed(1)
```

# Agenda

-   Problem statement
-   Go through the lab's tasks
-   Office hours

# 

\section{Problem statement}

# Problem statement

Data points $Y_1, Y_2, \dots, Y_n$ coming from a **mixture model**: $$
  Y_i \sim \sum_{j=1}^n w_j N(\mu_j, \varepsilon^2).
$$ \pause

**What does this mean?**\pause

For every data point:\pause

-   let $Z_i$ be a random variable such that $\mathbb{P}(Z_i = j) = w_j$ for $j=1,2,3$,\pause
-   let $Y_i \mid Z_i \sim N(\mu_{Z_i}, \varepsilon^2)$.

# Problem statement

Let's see what this mixture model could look like in an example.\pause

Let $\mu_1 = -5$, $\mu_2 = 0$ and $\mu_3 = 5$, and let $\varepsilon = 1$. Let $w_j = 1/3$ for $j = 1,2,3$.\pause

Now let's generate data from the mixture model:

\small

```{r, eval = FALSE}
n = 100
mu = c(-5, 0, 5)
  
Z = sample(1:3, size=n, replace=TRUE)
Y = rnorm(n, mean=mu[Z], sd=1)

hist(Y, breaks=20)
```

\normalfont

# Problem statement

```{r, eval = TRUE, echo=FALSE}
n = 100
mu = c(-5, 0, 5)
  
Z = sample(1:3, size=n, replace=TRUE)
Y = rnorm(n, mean=mu[Z], sd=1)

hist(Y, breaks=20)
```

# Problem statement

We have the model 
$$
  Y_i \sim \sum_{j=1}^n w_j N(\mu_j, \varepsilon^2),
$$
\pause now we need priors on the unknown parameters $\mu_j$, $w_j$ and $\varepsilon$.\pause

## Priors

**For the means:**
\begin{align*}
  \mu_j \mid \mu_0, \sigma_0 &\sim N(\mu_0, \sigma_0^2)\\\pause
  \mu_0 &\sim N(0,3)\\\pause
  \sigma_0^2 &\sim IG(2,2)\pause
\end{align*}
and recall that $\sigma_0^2\sim IG(2,2)$ means that $\phi_0 = 1/\sigma_0^2 \sim \text{Gamma}(2,2)$.

# Problem statement

## Priors

**For the mixture weights:**
$$
  (w_1, w_2, w_3) \sim \text{Dirichlet}(\boldsymbol{1})\pause
$$
which means that $p(w_1, w_2, w_3) \propto 1$.\pause

Recall that, in general, 
\begin{align*}
&(w_1, w_2, w_3) \sim \text{Dirichlet}(\alpha_1, \alpha_2, \alpha_3)\\ 
\Rightarrow &p(w_1, w_2, w_3) \propto w_1^{\alpha_1-1} w_2^{\alpha_2-1} w_3^{\alpha_3-1}.
\end{align*}


# Problem statement

## Priors

**For the variance:**
$$
  \varepsilon^2 \sim IG(2,2)
$$
\pause

This means that
$$
  \tau = 1/\varepsilon^2 \sim \text{Gamma}(2,2)
$$

# Problem statement

In summary,
\begin{align*}
p(Y_i | \mu_1,\mu_2,\mu_3,w_1,w_2,w_3,\tau) &= \sum_{j=1}^3 w_i N(\mu_j, \tau^{-1})\\
\mu_j|\mu_0,\sigma_0^2 &\sim N(\mu_0,\phi_0^{-1})\\
\mu_0 &\sim N(0,3)\\
\phi_0 &\sim \text{Gamma}(2,2)\\
(w_1,w_2,w_3) &\sim Dirichlet(\mathbf{1})\\
\tau &\sim \text{Gamma}(2,2),
\end{align*}
for $i=1,\ldots n.$

# Task 1

**Derive the joint posterior $p(w_1,w_2,w_3,\mu_1,\mu_2,\mu_3,\varepsilon^2,\mu_0,\sigma_0^2|Y_{1:N})$ up to a normalizing constant.**
\pause

Let's do the derivations using $\tau = 1/\varepsilon^2$ and $\phi_0 = 1/\sigma_0^2$.\pause

The posterior distribution is always proportional to the full joint distribution:\pause
\begin{align*}
&p(Y_{1:n}, \mu_{1:3}, \mu_0, \phi_0, w_{1:3}, \tau) \\\pause
= &p(Y_{1:n} \mid \mu_{1:3}, w_{1:3}, \tau) p(\mu_{1:3}, \mu_0, \phi_0, w_{1:3}, \tau)\\\pause
= & p(Y_{1:n} \mid \mu_{1:3}, w_{1:3}, \tau)p(\mu_{1:3} \mid \mu_0, \phi_0)p(\mu_0) p(\phi_0) p(w_{1:3}) p(\tau)\\\pause
= & p(Y_{1:n} \mid \mu_{1:3}, w_{1:3}, \tau)p(\mu_{1:3} \mid \mu_0, \phi_0)p(\mu_0) p(\phi_0) p(\tau)\\\pause
= & \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)p(\phi_0)p(\tau).
\end{align*}

# Task 1

The full joint:
$$
\left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)p(\phi_0)p(\tau).\pause
$$

And
$$
  p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) = \sum_{j=1}^3 w_j N(Y_i; \mu_j, \tau),\pause
$$
$$
p(\mu_j \mid \mu_0, \phi_0) = N(\mu_j; \mu_0, \phi_0^{-1}),\pause
$$
$$
  p(\mu_0) = N(\mu_0; 0,3),\pause
$$
$$
  p(\phi_0) = \text{Gamma}(\phi_0; 2,2),\pause
$$
$$
  p(\tau) = \text{Gamma}(\tau; 2,2).
$$

# Task 2

**Derive the full conditionals for all the parameters up to a normalizing constant.**

\begin{align*}
  &p(w\mid - )\\\pause
  \propto & \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)p(\phi_0)p(\tau)\\\pause
  \propto & \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right)\\\pause
  \propto& \prod_{i=1}^n \left(\sum_{j=1}^3 w_j N(Y_i; \mu_j, \tau)\right)
\end{align*}

# Task 2

\begin{align*}
  &p(\mu_j \mid - )\\\pause
  \propto & \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)p(\phi_0)p(\tau)\\\pause
  \propto& \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) p(\mu_j \mid \mu_0, \phi_0)\\\pause
  \propto& \left(\prod_{i=1}^n \left(\sum_{j=1}^3 w_j N(Y_i; \mu_j, \tau)\right)\right) p(\mu_j \mid \mu_0, \phi_0)
\end{align*}

# Task 2

\begin{align*}
  &p(\tau \mid -) \\\pause
  \propto & \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)p(\phi_0)p(\tau)\\\pause
  \propto& \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right)p(\tau)\\\pause
  \propto& \left(\prod_{i=1}^n \left(\sum_{j=1}^3 w_j N(Y_i; \mu_j, \tau)\right)\right) \tau^{2-1}\exp\{-2\tau\}.
\end{align*}

# Task 2

\begin{align*}
  &p(\mu_0 \mid -) \\\pause
  \propto & \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)p(\phi_0)p(\tau)\\\pause
  \propto& \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)\\\pause
  \propto& \exp\left\{-\frac{\phi_0}{2}\sum_{j=1}^3(\mu_j - \mu_0)^2\right\}\exp\{\mu_0^2/6\}\\\pause
  \propto& \exp\left\{-\frac{1}{2}\left[(3\phi_0  + \frac{1}{3})\mu_0^2 - 2 \mu_0 \phi_0\sum_{j=1}^3 \mu_j  \right]\right\}\\\pause
  \Rightarrow& \mu_0 \mid - \sim N\left((3\phi_0  + \frac{1}{3})^{-1}\phi_0\sum_{j=1}^3 \mu_j, (3\phi_0  + \frac{1}{3})^{-1}\right).
\end{align*}

# Task 2

\begin{align*}
  &p(\phi_0 \mid -) \\\pause
  \propto & \left(\prod_{i=1}^n p(Y_i \mid \mu_{1:3}, w_{1:3}, \tau) \right) \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\mu_0)p(\phi_0)p(\tau)\\\pause
  \propto& \left(\prod_{j=1}^3 p(\mu_j \mid \mu_0, \phi_0) \right) p(\phi_0)\\\pause
  \propto& \left(\prod_{j=1}^3\sqrt{\frac{\phi_0}{2\pi}}\exp\left\{-\frac{\phi_0}{2} (\mu_0 - \mu_j)^2\right\} \right)\phi_0^{2-1} \exp\{-2\phi_0\}\\\pause
  \propto& \phi_0^{7/2 - 1} \exp\left\{-\phi_0 \left(2 + \frac{1}{2}\sum_{j=1}^3(\mu_0 - \mu_j)^2\right)\right\}\\\pause
  \Rightarrow& \phi_0 \mid - \sim \text{Gamma}\left(7/2, 2 + \frac{1}{2}\sum_{j=1}^3(\mu_0 - \mu_j)^2\right)
\end{align*}



